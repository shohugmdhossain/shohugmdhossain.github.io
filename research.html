<!doctype html>
<html lang="en">
<head>
  <title>Research — M S Hossain</title>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="description" content="Research by Md Shohug Hossain — GeoAI, remote sensing, and planetary surface analysis across Earth and Mars.">
  <meta name="keywords" content="GeoAI, Remote Sensing, Planetary Science, Mars, Earth Observation, Machine Learning, Shohug Hossain">
  <meta name="author" content="Md Shohug Hossain">
  <link rel="canonical" href="https://shohugmdhossain.github.io/research.html">
  <meta name="theme-color" content="#b1040e">
  <meta property="og:type" content="website">
  <meta property="og:title" content="Research — M S Hossain">
  <meta property="og:description" content="GeoAI and remote sensing research by Md Shohug Hossain.">
  <meta property="og:image" content="https://shohugmdhossain.github.io/profile.jpg">
  <meta property="og:url" content="https://shohugmdhossain.github.io/research.html">
  <meta name="twitter:card" content="summary_large_image">
  <link rel="icon" href="favicon.ico" type="image/x-icon">

  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;600&family=Libre+Baskerville:wght@400;700&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/all.min.css">

  <style>
    :root{
      --accent:#b1040e; --bg:#fff; --bg2:#f9f9f9;
      --text:#222; --muted:#555; --line:#ddd; --max:1100px;
    }

    html,body{height:100%;scroll-behavior:smooth;}
    body{margin:0;background:var(--bg);color:var(--text);
      font-family:Inter,system-ui,Segoe UI,Roboto,Arial,sans-serif;line-height:1.75;}

    a{color:var(--accent);text-decoration:none;border-bottom:1px solid transparent;transition:.2s;}
    a:hover{border-bottom-color:var(--accent);}
    .wrap{max-width:var(--max);margin:0 auto;padding:0 20px;}

    /* ===== NAVBAR (matches About) ===== */
    .site-header{position:fixed;top:0;left:0;right:0;background:var(--accent);
      color:#fff;z-index:1000;box-shadow:0 3px 10px rgba(0,0,0,.1);}
    .nav-bar{display:flex;align-items:center;justify-content:space-between;padding:14px 0;}
    .brand{font-family:"Libre Baskerville",serif;font-weight:700;font-size:22px;color:#fff;}
    .brand a{color:#fff;text-decoration:none;}
    .nav-links{display:flex;gap:20px;align-items:center;}
    .nav-links a{color:#fff;font-size:15px;}
    .nav-links a:hover,.nav-links a.active{text-decoration:underline;opacity:.9;}
    .right-cluster{display:flex;align-items:center;gap:14px;}
    .menu-toggle{background:none;border:none;color:#fff;font-size:24px;cursor:pointer;}
    .menu-toggle:hover{transform:scale(1.1);}
    .search-box input{border:none;border-radius:8px;background:rgba(255,255,255,.95);
      color:#222;padding:7px 10px;width:170px;transition:width .25s;}
    .search-box input:focus{outline:none;width:220px;}

    /* ===== OVERLAY MENU (matches About) ===== */
    .dropdown-nav{position:fixed;top:0;left:0;right:0;bottom:0;
      background:rgba(177,4,14,.75);backdrop-filter:blur(10px);
      display:flex;flex-direction:column;align-items:center;justify-content:center;
      gap:24px;z-index:9999;opacity:0;visibility:hidden;transition:.3s;}
    .dropdown-nav.active{opacity:1;visibility:visible;}
    .dropdown-nav a{color:#fff;font-size:22px;font-weight:500;}
    .dropdown-close{position:absolute;top:20px;right:28px;color:#fff;font-size:26px;
      border:none;background:none;cursor:pointer;}

    /* ===== PAGE LAYOUT ===== */
    main{margin-top:100px;margin-bottom:80px;}
    .section{margin-bottom:60px;}
    .section h1{font-size:30px;color:var(--accent);margin-bottom:15px;}
    .section h2{color:var(--accent);font-size:22px;margin-bottom:12px;display:flex;align-items:center;gap:10px;}
    .section h2 i{color:var(--accent);}
    .section p{font-size:16px;line-height:1.85;text-align:justify;max-width:950px;margin:0 auto 14px;}
    .key-list{max-width:950px;margin:10px auto 14px;padding-left:18px;}
    .key-list li{margin:6px 0;}

    /* ===== FOOTER ===== */
    footer.site{background:var(--accent);color:#fff;text-align:center;margin-top:80px;}
    footer.site .wrap{padding:20px;}
    footer.site p{margin:0;font-size:15px;}
    #toTop{position:fixed;bottom:20px;right:20px;background:var(--accent);
      color:#fff;border:none;border-radius:50%;width:42px;height:42px;
      font-size:18px;cursor:pointer;display:none;z-index:999;}
    #toTop.show{display:block;}
  </style>
</head>

<body>
  <!-- ===== NAVBAR ===== -->
  <header class="site-header">
    <div class="wrap nav-bar">
      <div class="brand"><a href="index.html">M S Hossain</a></div>
      <nav class="nav-links">
        <a href="about.html">About</a>
        <a href="research.html" class="active">Research</a>
        <a href="experience.html">Experience</a>
        <a href="publications.html">Publications</a>
        <a href="awards.html">Awards</a>
        <a href="contact.html">Contact</a>
      </nav>
      <div class="right-cluster">
        <div class="search-box">
          <form action="https://www.google.com/search" method="get" target="_blank">
            <input type="text" name="q" placeholder="Search..." id="searchInput">
            <input type="hidden" name="sitesearch" value="shohugmdhossain.github.io">
          </form>
        </div>
        <button class="menu-toggle" aria-label="Toggle menu"><i class="fas fa-bars"></i></button>
      </div>
    </div>
  </header>

  <!-- ===== OVERLAY MENU ===== -->
  <div class="dropdown-nav" id="overlayMenu">
    <button class="dropdown-close" aria-label="Close menu"><i class="fas fa-times"></i></button>
    <a href="about.html">About</a>
    <a href="research.html" class="active">Research</a>
    <a href="experience.html">Experience</a>
    <a href="publications.html">Publications</a>
    <a href="awards.html">Awards</a>
    <a href="contact.html">Contact</a>
  </div>

  <!-- ===== MAIN ===== -->
  <main class="wrap">

    <!-- Research Overview -->
    <section class="section">
      <h1>Research Overview</h1>
      <p>
        My research lies at the intersection of <b>GeoAI, remote sensing, and planetary geomorphology</b>. I develop machine-learning
        systems to detect, map, and interpret surface features across Earth and Mars, integrating <b>physics-informed modeling</b>,
        <b>multi-sensor data fusion</b>, and <b>high-performance computing (HPC)</b>. Methodologically, I focus on trustworthy pipelines,
        rigorous dataset curation, and reproducible evaluation — balancing accuracy, interpretability, and scientific utility.
      </p>
    </section>

    <!-- Planetary GeoAI -->
    <section class="section" id="planetary-geoai">
      <h2><i class="fa-solid fa-mars"></i> Planetary GeoAI: Mars Mound Detection</h2>
      <p>
        I build object-detection pipelines to identify mounds and crater-like landforms in <b>CTX</b> imagery. Architectures include
        <b>Faster R-CNN (ResNet-50-FPN)</b> via Detectron2 and <b>YOLOv8</b> variants. Early runs exposed important dataset issues:
        overlapping categories (<i>“mounds-rVCN”</i> and <i>“mounds”</i>) produced class-metadata conflicts, while unlabeled/empty entries
        in COCO caused zero-AP evaluations. I rebuilt the dataset as a single-class (<i>“mound”</i>) COCO set, filtered empty images,
        and verified <code>category_id</code> mappings. This restored stable validation and test metrics.
      </p>
      <p>
        On the <b>LONI A100</b> HPC (QB-3/4), I trained and evaluated with custom Slurm scripts (e.g., <i>evaluate_mounds_fixed.py</i>,
        <i>evaluate_mounds_long.py</i>, <i>infer_mounds.py</i>, <i>visualize_predictions.py</i>) and organized outputs under a consistent
        structure (<code>/work/shohug/Mars_CTX/Mounds_2/Mounds2/{train,valid,test,outputs}</code>). After dataset repairs, the
        single-class setup yielded moderate validation results (~<b>56% AP50</b>) and test ~<b>59% AP50</b>, with overall accuracy still
        constrained (~28–30%) due to underfitting when the classifier head re-initialized. I’m extending training schedules and
        augmentations (mosaic/cutout, scale jitter, brightness/contrast) to improve recall.
      </p>
      <p>
        Current directions include (i) <b>two-class</b> mapping to distinguish morphologies (<i>mounds</i> vs <i>mounds-rVCN</i>) using
        <code>ROI_HEADS.NUM_CLASSES=2</code> and explicit class mapping, (ii) <b>physics-aware post-filtering</b> (shape/relief priors),
        (iii) <b>domain-adaptive fine-tuning</b> for CTX regions with different SNR/sun angles, and (iv) <b>joint inference</b> with
        neighboring context tiles to stabilize predictions at tile edges. All runs are versioned; logs, COCO evals, and visualizations
        are exported (CSV/PDF/PNG) for transparent comparison.
      </p>
      <ul class="key-list">
        <li><b>Data:</b> Roboflow-COCO (CTX tiles, filtered to labeled imagery; consistent <code>category_id</code>).</li>
        <li><b>Models:</b> Faster-RCNN-R50-FPN, YOLOv8; moving toward multi-class heads with calibrated thresholds.</li>
        <li><b>HPC:</b> LONI A100 queues; Slurm jobs for training/eval; artifact logging and reproducible seeds.</li>
        <li><b>Metrics:</b> COCO AP/AP50/AP75; precision-recall trade-offs; qualitative overlays for geomorphic plausibility.</li>
      </ul>
    </section>

    <!-- Earth Observation & Walkability -->
    <section class="section" id="walkability">
      <h2><i class="fa-solid fa-earth-americas"></i> Earth Observation & Walkability Mapping</h2>
      <p>
        I lead a sidewalk-assets and walkability project combining aerial/street-level imagery with deep learning to map
        accessibility features. Beyond overall accuracy, stakeholders needed <b>per-feature metrics</b> — buffers, curb ramps,
        traffic control, marked crosswalks, sidewalks, and surfaces. I expanded evaluation to produce <b>confusion matrices</b> and
        per-feature precision/recall/F1, enabling targeted error analysis and label-quality improvements.
      </p>
      <p>
        Using a curated <b>300-sample validation dataset</b>, I implemented analysis scripts (<i>analysis/merge_results.py</i>,
        <i>auto_label_review.py</i>, <i>extract_low_accuracy_sets.py</i>) to flag low-confidence/mismatch cases for manual review.
        After a focused re-label pass (23–25 items), we observed measurable gains: the largest was
        <b>traffic_control_T</b> (+0.128 F1), with improvements on <b>surface_T</b> (+0.075), <b>curb_ramp_T</b> (+0.019),
        and <b>buffer_T</b> (+0.017), while <b>sidewalk_T</b> and <b>marked_crosswalk_T</b> remained stable. Deliverables included
        side-by-side <i>Before/After</i> F1 tables, confusion matrices, and rationale summarizing the impact of label quality.
      </p>
      <p>
        Next steps prioritize (i) <b>hard-negative mining</b> for look-alike urban features, (ii) <b>temporal robustness</b> checks across
        seasons/lighting, (iii) <b>uncertainty estimates</b> for map layers (e.g., MC-dropout or deep ensembles), and (iv) integrating
        a <b>human-in-the-loop</b> cycle that routes low-confidence detections to reviewers, improving datasets over time.
      </p>
      <ul class="key-list">
        <li><b>Data:</b> Mixed aerial/street-level; 300-sample validation subset for per-feature scoring.</li>
        <li><b>Models:</b> YOLO-based detectors with class-wise thresholds; optional two-stage refinement for small objects.</li>
        <li><b>Evaluation:</b> Per-feature confusion matrices; drift checks; error slices by context (intersection type, lighting).</li>
        <li><b>Outputs:</b> CSV/PDF/PNG packs; summary briefs for urban-planning stakeholders.</li>
      </ul>
    </section>

    <!-- Physics-Informed ML & Data Fusion -->
    <section class="section" id="pinn-fusion">
      <h2><i class="fa-solid fa-atom"></i> Physics-Informed Machine Learning & Multi-Sensor Fusion</h2>
      <p>
        I’m advancing <b>physics-informed neural networks</b> and <b>multi-sensor fusion</b> (optical, radar, thermal) to improve
        generalization and interpretability for both terrestrial and planetary analyses. On Earth, fusing <b>SAR</b> backscatter with
        optical indices enhances surface/structure discrimination under cloud or low-light conditions; on Mars, combining CTX-scale
        morphology with illumination/photometric context constrains false positives and supports more stable detection thresholds.
      </p>
      <p>
        The framework integrates <b>soft physical priors</b> (e.g., plausible shape/texture ranges, slope/relief relationships),
        <b>uncertainty-aware calibration</b> (temperature scaling, conformal prediction), and <b>cross-modal attention</b> to guide the
        model toward geophysically plausible solutions. On HPC, I orchestrate <b>multi-GPU</b> experiments, tracking runs with
        reproducible configs and artifact logging to enable ablation and sensitivity studies.
      </p>
      <ul class="key-list">
        <li><b>Fusion:</b> Optical-SAR-thermal stacks; tile-edge context windows; attention across modalities/scales.</li>
        <li><b>Physics priors:</b> Morphological constraints, relief/illumination cues, topographic context where available.</li>
        <li><b>Trust & QA:</b> Uncertainty-aware maps; calibrated thresholds; reviewer routing for low-confidence tiles.</li>
        <li><b>HPC:</b> Distributed training/eval on LONI A100; versioned runs; scripted exports (CSV/PDF/PNG).</li>
      </ul>
    </section>
  </main>

  <!-- ===== FOOTER ===== -->
  <footer class="site">
    <div class="wrap"><p>© <span id="y"></span> Md Shohug Hossain · GeoAI & Remote Sensing</p></div>
  </footer>

  <button id="toTop" aria-label="Back to top"><i class="fa-solid fa-chevron-up"></i></button>

  <script>
    document.addEventListener('DOMContentLoaded',()=>{
      const y=document.getElementById('y');
      if(y)y.textContent=new Date().getFullYear();

      const overlay=document.getElementById('overlayMenu');
      const toggle=document.querySelector('.menu-toggle');
      const closeBtn=document.querySelector('.dropdown-close');
      const toTop=document.getElementById('toTop');

      const openMenu=()=>overlay.classList.add('active');
      const closeMenu=()=>overlay.classList.remove('active');
      toggle.addEventListener('click',openMenu);
      closeBtn.addEventListener('click',closeMenu);
      overlay.addEventListener('click',e=>{if(e.target===overlay)closeMenu();});
      document.addEventListener('keydown',e=>{if(e.key==='Escape')closeMenu();});

      window.addEventListener('scroll',()=>{
        toTop.classList.toggle('show',window.scrollY>200);
      });
      toTop.addEventListener('click',()=>window.scrollTo({top:0,behavior:'smooth'}));
    });
  </script>
</body>
</html>























